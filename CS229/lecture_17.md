[<< Lecture 16](lecture_16.md) ‚Ä¢ [Lecture 18 >>](lecture_18.md)
## Lecture 17 - MDPs & Value/Policy Iteration

[![Lecture 17 - MDPs & Value/Policy Iteration | Stanford CS229: Machine Learning Andrew Ng (Autumn2018)](https://markdown-videos-api.jorgenkh.no/url?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Dd5gaWTo6kDM%26list%3DPLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU%26index%3D17)](https://www.youtube.com/watch?v=d5gaWTo6kDM&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&index=17)

### Overview

### Timestamps
  
[0:30](https://youtu.be/d5gaWTo6kDM?si=Mg8bywFAcgt5Fj7y&t=30): ü§ñ Exciting application of autonomous robotics: InSight Mars lander attempting to land on Mars in 2.5 hours, 20 light minutes away from Earth.  
[5:37](https://youtu.be/d5gaWTo6kDM?si=Mg8bywFAcgt5Fj7y&t=337): üéì Learning to compute optimal policy in MDPs with large number of possible policies.  
[11:40](https://youtu.be/d5gaWTo6kDM?si=Mg8bywFAcgt5Fj7y&t=700): ü§ñ Understanding the concept of expected payoff in Markov Decision Processes.  
[18:06](https://youtu.be/d5gaWTo6kDM?si=Mg8bywFAcgt5Fj7y&t=1086): üéì Understanding the Policy Iteration process in MDPs  
[24:47](https://youtu.be/d5gaWTo6kDM?si=Mg8bywFAcgt5Fj7y&t=1487): üìö Introduction to Optimal Value Function V star in MDPs  
[31:30](https://youtu.be/d5gaWTo6kDM?si=Mg8bywFAcgt5Fj7y&t=1890): üéì Optimal policy computation using argmax and V star  
[38:47](https://youtu.be/d5gaWTo6kDM?si=Mg8bywFAcgt5Fj7y&t=2327): ‚è≥ Synchronous vs. Asynchronous Update in Gradient Descent  
[44:00](https://youtu.be/d5gaWTo6kDM?si=Mg8bywFAcgt5Fj7y&t=2640): ‚è≥ Convergence of Value Iteration in MDPs  
[51:49](https://youtu.be/d5gaWTo6kDM?si=Mg8bywFAcgt5Fj7y&t=3109): üí° Comparison of Value Iteration and Policy Iteration  
[56:54](https://youtu.be/d5gaWTo6kDM?si=Mg8bywFAcgt5Fj7y&t=3414): ‚öôÔ∏è Comparison of Value Iteration and Policy Iteration in solving for optimal value and policy.  
[1:03:28](https://youtu.be/d5gaWTo6kDM?si=Mg8bywFAcgt5Fj7y&t=3808): ‚öôÔ∏è MDP Solver Process and Value Iteration  
[1:09:47](https://youtu.be/d5gaWTo6kDM?si=Mg8bywFAcgt5Fj7y&t=4187): ü§ñ Algorithm's Greedy Approach and Lack of Exploration in MDPs  
[1:15:05](https://youtu.be/d5gaWTo6kDM?si=Mg8bywFAcgt5Fj7y&t=4505): ü§î Misconception about Epsilon-greedy exploration in reinforcement learning.

Timestamps by Tammy AI

[<< Lecture 16](lecture_16.md) ‚Ä¢ [Lecture 18 >>](lecture_18.md)