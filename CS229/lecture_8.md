[<< Lecture 7](lecture_7.md) • [Lecture 9 >>](lecture_9.md)
## Lecture 8 - Data Splits, Models and Cross-Validation

[![Lecture 8 - Data Splits, Models & Cross-Validation | Stanford CS229: Machine Learning (Autumn 2018)](https://markdown-videos-api.jorgenkh.no/url?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DrjbkWSTjHzM%26list%3DPLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU%26index%3D8)](https://www.youtube.com/watch?v=rjbkWSTjHzM&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&index=8)

### Overview

### Timestamps
  
[0:41](https://youtu.be/rjbkWSTjHzM?si=95UIrOltvhaERaxW&t=41): 😅 Bias and variance is a concept that is easy to understand but hard to master in machine learning.  
[5:45](https://youtu.be/rjbkWSTjHzM?si=95UIrOltvhaERaxW&t=345): 📊 Different models are used to fit a dataset, with a quadratic model being the best fit.  
[12:02](https://youtu.be/rjbkWSTjHzM?si=95UIrOltvhaERaxW&t=722): 📚 Regularization is an effective technique to prevent overfitting in machine learning models.  
[20:00](https://youtu.be/rjbkWSTjHzM?si=95UIrOltvhaERaxW&t=1200): 🔬 The support vector machine (SVM) doesn't overfit because it minimizes the norm of w squared, which corresponds to maximizing the margin.  
[25:05](https://youtu.be/rjbkWSTjHzM?si=95UIrOltvhaERaxW&t=1505): 🏠 The video discusses the importance of normalizing features in machine learning.  
[32:57](https://youtu.be/rjbkWSTjHzM?si=95UIrOltvhaERaxW&t=1977): 📊 There are two main schools of statistics: frequentist and Bayesian, and statisticians now freely switch between the two.  
[39:30](https://youtu.be/rjbkWSTjHzM?si=95UIrOltvhaERaxW&t=2370): ✅ Regularization helps prevent overfitting and underfitting in linear regression models.  
[47:18](https://youtu.be/rjbkWSTjHzM?si=95UIrOltvhaERaxW&t=2838): 📊 It is important to evaluate the algorithm on a separate test set and report the error for unbiased results when publishing a paper or reporting results.  
[54:04](https://youtu.be/rjbkWSTjHzM?si=95UIrOltvhaERaxW&t=3244): 📊 As datasets get larger, the percentage of data allocated to development and testing decreases.  
[59:44](https://youtu.be/rjbkWSTjHzM?si=95UIrOltvhaERaxW&t=3584): 💡 When building a machine learning system, it is important to split the dataset into train, dev, and test sets, optimize the algorithm's performance on the dev set, and evaluate the final model on the test set without making decisions based on it.  
[1:06:06](https://youtu.be/rjbkWSTjHzM?si=95UIrOltvhaERaxW&t=3966): ✅ The video explains the process of cross-validation for model evaluation.  
[1:12:38](https://youtu.be/rjbkWSTjHzM?si=95UIrOltvhaERaxW&t=4358): 📚 K-fold cross-validation is rarely used in deep learning algorithms due to the time it takes to train and the need for a larger dataset.  
[1:18:08](https://youtu.be/rjbkWSTjHzM?si=95UIrOltvhaERaxW&t=4688): 🔍 Feature selection is the process of finding a small subset of the most relevant features for a task.  
  
Timestamps by Tammy AI

[<< Lecture 7](lecture_7.md) • [Lecture 9 >>](lecture_9.md)