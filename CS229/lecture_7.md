[<< Lecture 6](lecture_6.md) ‚Ä¢ [Lecture 8 >>](lecture_8.md)
## Lecture 7 - Kernels

[![Lecture 7 - Kernels | Stanford CS229: Machine Learning Andrew Ng (Autumn 2018)](https://markdown-videos-api.jorgenkh.no/url?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D8NYoQiRANpg%26list%3DPLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU%26index%3D7)](https://www.youtube.com/watch?v=8NYoQiRANpg&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&index=7)

### Overview

* Representor Theorem
* Kernels
* Applications of Support Vector Machines

### Timestamps
  
[0:13](https://youtu.be/8NYoQiRANpg?si=81OzZwLUwgsyMaBL&t=13): üìö The Support Vector Machine Algorithm is a turnkey solution for classification problems and can work in high-dimensional feature spaces.  
[5:37](https://youtu.be/8NYoQiRANpg?si=81OzZwLUwgsyMaBL&t=337): üìö The video explains the concept of geometric margin in an optimization problem and how to maximize it.  
[12:07](https://youtu.be/8NYoQiRANpg?si=81OzZwLUwgsyMaBL&t=727): üìö The video discusses the assumption that W can be represented as a linear combination of training examples in primal dual optimization.  
[18:00](https://youtu.be/8NYoQiRANpg?si=81OzZwLUwgsyMaBL&t=1080): üìö The video explains how the values of W and B affect the decision boundary in high dimensional feature spaces.  
[25:09](https://youtu.be/8NYoQiRANpg?si=81OzZwLUwgsyMaBL&t=1509): üìö The video discusses the optimization algorithm in support vector machines and introduces the dual optimization problem.  
[31:44](https://youtu.be/8NYoQiRANpg?si=81OzZwLUwgsyMaBL&t=1904): üìö The video explains the concept of kernel functions in machine learning.  
[37:48](https://youtu.be/8NYoQiRANpg?si=81OzZwLUwgsyMaBL&t=2268): üìä The video discusses the computation of x transpose z and its square in order n time.  
[44:23](https://youtu.be/8NYoQiRANpg?si=81OzZwLUwgsyMaBL&t=2663): üìö Support Vector Machines (SVM) are classifiers that use the optimal margin classifier and the kernel trick to handle high-dimensional feature spaces efficiently.  
[50:37](https://youtu.be/8NYoQiRANpg?si=81OzZwLUwgsyMaBL&t=3037): üìö The video discusses the concept of similarity between vectors and how it relates to the inner product.  
[58:12](https://youtu.be/8NYoQiRANpg?si=81OzZwLUwgsyMaBL&t=3492): üìö The video discusses the concept of positive semi-definite kernel functions and their implications.  
[1:05:10](https://youtu.be/8NYoQiRANpg?si=81OzZwLUwgsyMaBL&t=3910): üîç The video discusses the importance of not assuming linear separability in data and the need for learning algorithms to allow for some errors in classification.  
[1:10:22](https://youtu.be/8NYoQiRANpg?si=81OzZwLUwgsyMaBL&t=4222): üí° The L_1 soft margin SVM is a more robust version of the basic optimal margin classifier that allows for the presence of outliers.  
[1:15:52](https://youtu.be/8NYoQiRANpg?si=81OzZwLUwgsyMaBL&t=4552): üß¨ Proteins are made up of sequences of amino acids, and the video discusses how to represent these sequences.  
  
Timestamps by Tammy AI

[<< Lecture 6](lecture_6.md) ‚Ä¢ [Lecture 8 >>](lecture_8.md)