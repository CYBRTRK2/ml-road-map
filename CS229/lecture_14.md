[<< Lecture 13](lecture_13.md) ‚Ä¢ [Lecture 15 >>](lecture_15.md)
## Lecture 14 - Expectation-Maximization Algorithms

[![Lecture 14 - Expectation-Maximization Algorithms | Stanford CS229: Machine Learning (Autumn 2018)](https://markdown-videos-api.jorgenkh.no/url?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DrVfZHWTwXSA%26list%3DPLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU%26index%3D14)](https://www.youtube.com/watch?v=rVfZHWTwXSA&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&index=14)

### Overview

### Timestamps
  
[0:14](https://youtu.be/rVfZHWTwXSA?si=3yjVlqfyWcmdTdSf&t=14): üìö The video discusses the logistical details of the upcoming midterm and introduces the topic of unsupervised learning.  
[4:50](https://youtu.be/rVfZHWTwXSA?si=3yjVlqfyWcmdTdSf&t=290): ! The video explains the k-means clustering algorithm and its convergence.  
[12:29](https://youtu.be/rVfZHWTwXSA?si=3yjVlqfyWcmdTdSf&t=749): ! The k-means algorithm can be proven to converge by minimizing a cost function that measures the square distance between each point and its assigned cluster centroid.  
[17:01](https://youtu.be/rVfZHWTwXSA?si=3yjVlqfyWcmdTdSf&t=1021): üîß The video discusses the problem of density estimation in the context of anomaly detection in aircraft engines.  
[21:16](https://youtu.be/rVfZHWTwXSA?si=3yjVlqfyWcmdTdSf&t=1276): üìä The video discusses the concept of mixture of Gaussians model for anomaly detection.  
[27:22](https://youtu.be/rVfZHWTwXSA?si=3yjVlqfyWcmdTdSf&t=1642): ‚úçÔ∏è The speaker discusses the difference between Gaussian discriminant analysis and using a latent random variable z_i in the training set.  
[34:39](https://youtu.be/rVfZHWTwXSA?si=3yjVlqfyWcmdTdSf&t=2079): üìä The video explains the E-step and M-step in the Expectation-Maximization algorithm for maximum likelihood estimation.  
[40:59](https://youtu.be/rVfZHWTwXSA?si=3yjVlqfyWcmdTdSf&t=2459): üìö The EM algorithm is a maximum likelihood estimation algorithm that converges at least to a local optimum.  
[47:08](https://youtu.be/rVfZHWTwXSA?si=3yjVlqfyWcmdTdSf&t=2828): üé• The video discusses the EM algorithm for the mixture of Gaussians and its applications.  
[52:40](https://youtu.be/rVfZHWTwXSA?si=3yjVlqfyWcmdTdSf&t=3160): üìö The video discusses Jensen's inequality and the concept of convex functions.  
[59:52](https://youtu.be/rVfZHWTwXSA?si=3yjVlqfyWcmdTdSf&t=3592): üìä The video explains the EM algorithm, an iterative algorithm for finding the maximum likelihood estimates of parameters theta.  
[1:06:42](https://youtu.be/rVfZHWTwXSA?si=3yjVlqfyWcmdTdSf&t=4002): üí° The video explains the concept of expected value using Jensen's inequality.  
[1:15:06](https://youtu.be/rVfZHWTwXSA?si=3yjVlqfyWcmdTdSf&t=4506): üìö The speaker discusses the choice of distribution for z_i in a probability density function.  

Timestamps by Tammy AI

[<< Lecture 13](lecture_13.md) ‚Ä¢ [Lecture 15 >>](lecture_15.md)