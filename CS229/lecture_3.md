[<< Lecture 2](lecture_2.md) • [Lecture 4 >>](lecture_4.md)
## Lecture 3 - Locally Weighted and Logistic Regression

[![Locally Weighted & Logistic Regression | Stanford CS229: Machine Learning - Lecture 3 (Autumn 2018)](https://markdown-videos-api.jorgenkh.no/url?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Dhet9HFqo1TQ%26list%3DPLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU%26index%3D3)](https://www.youtube.com/watch?v=het9HFqo1TQ&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&index=3)

### Topics

* Locally Weighted Regression
* Logistic Regression
* Gaussian Density
* Maximum Likelihood Estimation

### Timestamps

[0:28](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=28): 📚 The video discusses supervised learning, specifically linear regression, locally weighted regression, and logistic regression.  
[5:38](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=338): 📚 Locally weighted regression is a non-parametric learning algorithm that requires keeping data in computer memory.  
[13:05](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=785): 📊 Locally weighted regression is a method that assigns different weights to data points based on their distance from the prediction point.  
[19:01](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=1141): 📚 Locally linear regression is a learning algorithm that may not have good results and is not great at extrapolation.  
[24:46](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=1486): 🔍 The video discusses Gaussian density and its application in determining housing prices.  
[31:31](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=1891): 💡 The likelihood of the parameters is the probability of the data given the parameters, assuming independent and identically distributed errors.  
[36:55](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=2215): 📊 Maximum Likelihood Estimation (MLE) is a commonly used method in statistics to estimate parameters by maximizing the likelihood or log-likelihood of the data.  
[43:44](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=2624): 📊 Applying linear regression to a binary classification problem is not a good idea.  
[49:22](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=2962): 🎯 The video discusses the choice of hypothesis function in learning algorithms and why logistic regression is chosen as a special case of generalized linear models.  
[54:45](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=3285): 📚 The video explains how to compress two equations into one line using a notational trick.  
[1:01:31](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=3691): ✏️ Batch gradient ascent is used to update the parameters in logistic regression.  
[1:07:52](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=4072): 📚 The video explains how to use Newton's method to find the maximum or minimum of a function.  
[1:13:55](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=4435): 💡 Newton's method is a fast algorithm for finding the place where the first derivative of a function is 0, using the first and second derivatives.  
  
Timestamps by Tammy AI

[<< Lecture 2](lecture_2.md) • [Lecture 4 >>](lecture_4.md)